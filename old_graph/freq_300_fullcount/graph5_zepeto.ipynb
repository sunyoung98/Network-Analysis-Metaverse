from ast import literal_eval
from collections import Counter
# 문자열을 리스트로 변환
def str_to_list(x):
    try:
        return literal_eval(x)
    except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기
        return None
    
origin_data=pd.read_csv("zep_selected_4.csv",index_col=0)
hate_data = origin_data[origin_data['score']<=2]
like_data = origin_data[origin_data['score']>=4]
medium_data = origin_data[origin_data['score']==3]

data_list = [origin_data, hate_data, like_data, medium_data]

for idx, data in enumerate(data_list):
  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))
  #data['word_set']=data['words_selected'].apply(lambda x: list(set(x)))
  words_list=[]
  for i in data['words_selected']:
    words_list+=i
  from collections import Counter
  c=Counter(words_list)
  c_dict= dict(c.most_common(300))
  count = {}   #동시출현 빈도가 저장될 dict
  for line in data['words_selected']:
      #하나의 문서에서 동일한 단어가 두번 나와도 두번의 동시출현으로 고려X
      words = line
      #한줄씩 읽어와서 단어별로 분리(unique한 값으로 받아오기)
      #split은 띄어쓰기를 단어로 구분하라는 함수
      for i, a in enumerate(words):
          for b in words[i+1:]:
              if a!=b:
                if a>b:
                    count[b, a] = count.get((b, a),0) + 1
                else :
                    count[a, b] = count.get((a, b),0) + 1
  df=pd.DataFrame.from_dict(count, orient='index')
  df.head()
  list1=[]
  for i in range(len(df)):
      #index를 중심으로 계속 중첩해서 list에 넣는다
      list1.append([df.index[i][0],df.index[i][1],df[0][i]])
  #pandas 이용해서 df형태로 만들기
  df2=pd.DataFrame(list1, columns=['term1','term2','freq'])
  #pandas 이용해서 sorting 하기 (디폴트가 오름차순이라서 false 꼭 써줘야 내림차순으로 나옴)
  df3=df2.sort_values(by=['freq'],ascending=False)
  import numpy as np
  import networkx as nx
  import operator
  G=nx.Graph()
  for i in range(len(df3)):
      G.add_edge(df3['term1'][i], df3['term2'][i], weight=int(df3['freq'][i]))
  nodes_to_remove = set(G.nodes()) - set(c_dict)  # 제거하지 않을 노드들의 집합
  G.remove_nodes_from(nodes_to_remove)
  if idx ==0:
    temp = 'origin'
  if idx == 1:
    temp = 'hate'
  if idx == 2:
    temp = 'like'
  if idx == 3:
    temp = 'medium'
  nx.write_graphml_lxml(G, 'zepeto_'+temp+'_graph5.graphml')
