{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1tPMFb2eEznOQLU65jwkTU2F4TzEpH1ob","authorship_tag":"ABX9TyOZGLKIE2KEvrw+v4BKsyUj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from ast import literal_eval\n","from collections import Counter\n","import csv\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","import itertools\n","\n","# 문자열을 리스트로 변환\n","def str_to_list(x):\n","    try:\n","        return literal_eval(x)\n","    except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기\n","        return None\n","\n","origin_data=pd.read_csv(\"/content/drive/MyDrive/성균관대/rob_selected_4.csv\", low_memory=False)\n","hate_data = origin_data[origin_data['score']<=2]\n","like_data = origin_data[origin_data['score']>=4]\n","medium_data = origin_data[origin_data['score']==3]\n","data_list = [origin_data, hate_data, like_data, medium_data]\n","\n","for idx, data in enumerate(data_list):\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n","  tfidf = TfidfVectorizer()\n","  tdm = tfidf.fit_transform(data['words_selected'])\n","  tf_idf = pd.DataFrame({\n","    '단어': tfidf.get_feature_names_out(),\n","    '빈도': tdm.sum(axis=0).flat})\n","  tf_idf = tf_idf.sort_values('빈도', ascending=False)\n","  tf_idf_dict = tf_idf.set_index('단어')['빈도'].to_dict()\n","  not_remove = dict(itertools.islice(tf_idf_dict.items(), 1000))\n","\n","  count_vec = CountVectorizer()\n","  con = count_vec.fit_transform(data['words_selected'])\n","  word_counts = np.array(con.sum(axis=0)).squeeze()\n","  # 단어-빈도수 사전 생성\n","  c_dict = dict(zip(count_vec.get_feature_names_out(), word_counts))\n","  # 빈도수를 기준으로 내림차순 정렬된 단어-빈도수 사전 생성\n","  c_dict = dict(sorted(c_dict.items(), key=lambda x: x[1], reverse=True))\n","  count = {}   #동시출현 빈도가 저장될 dict\n","  for line in data['words_selected']:\n","      #하나의 문서에서 동일한 단어가 두번 나와도 두번의 동시출현으로 고려X\n","      words = line.split(\" \")\n","      #한줄씩 읽어와서 단어별로 분리(unique한 값으로 받아오기)\n","      #split은 띄어쓰기를 단어로 구분하라는 함수 \n","      \n","      for i, a in enumerate(words):\n","          for b in words[i+1:]:\n","              if a!=b:\n","                if a>b: \n","                    count[b, a] = count.get((b, a),0) + 1  \n","                else :\n","                    count[a, b] = count.get((a, b),0) + 1\n","  df=pd.DataFrame.from_dict(count, orient='index')\n","  df.head()\n","  list1=[]\n","  for i in range(len(df)):\n","    #index를 중심으로 계속 중첩해서 list에 넣는다 \n","    list1.append([df.index[i][0],df.index[i][1],df[0][i]])\n","      \n","  #pandas 이용해서 df형태로 만들기 \n","  df2=pd.DataFrame(list1, columns=[\"term1\",\"term2\",\"freq\"])\n","  #pandas 이용해서 sorting 하기 (디폴트가 오름차순이라서 false 꼭 써줘야 내림차순으로 나옴)\n","  df3=df2.sort_values(by=['freq'],ascending=False)\n","  print(df3)\n","  import numpy as np\n","  import networkx as nx\n","  import operator\n","  G=nx.Graph()\n","  for key in c_dict:\n","      G.add_node(key, tfidf=tf_idf_dict[key], count=c_dict[key])\n","  for i in range(len(df3)):\n","      G.add_edge(df3['term1'][i], df3['term2'][i], weight=int(df3['freq'][i]))\n","  nodes_to_remove = set(G.nodes()) - set(not_remove)  # 제거하지 않을 노드들의 집합\n","  G.remove_nodes_from(nodes_to_remove)\n","  print(len(G.nodes), len(G.edges))\n","  if idx ==0:\n","      temp = \"origin\"\n","  if idx == 1:\n","      temp = \"hate\"\n","  if idx == 2:\n","      temp = \"like\"\n","  if idx == 3:\n","      temp = \"medium\"\n","  with open(\"/content/drive/MyDrive/성균관대/github/tf-idf/rob_\"+temp+\"_word_count.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key in c_dict:\n","       writer.writerow([key, c_dict[key]])\n","  with open(\"/content/drive/MyDrive/성균관대/github/tf-idf/rob_\"+temp+\"_tf_idf.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key in tf_idf_dict:\n","       writer.writerow([key, tf_idf_dict[key]])\n","  nx.write_graphml_lxml(G, \"/content/drive/MyDrive/성균관대/github/tf-idf/rob_\"+temp+\"_tf_idf_graph.graphml\")"],"metadata":{"id":"FdLM0aDnPT_Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682534997558,"user_tz":-540,"elapsed":136003,"user":{"displayName":"박선영","userId":"11923719610323479568"}},"outputId":"244faa71-e0e9-4cf4-a0bf-a5e7d00e8358"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["              term1     term2   freq\n","47             game      play  92383\n","54              fun      game  43851\n","425            game    people  25526\n","728          friend      game  22358\n","320            game     thing  22228\n","...             ...       ...    ...\n","492184       server  streamer      1\n","492188   filtration  platform      1\n","492190       clever  platform      1\n","492191     platform    swears      1\n","1077658       dosen  internet      1\n","\n","[1077659 rows x 3 columns]\n","1000 225827\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-71-8ba1fd9a21c9>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-71-8ba1fd9a21c9>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["           term1      term2  freq\n","211         game       play  9218\n","481          fix       game  4412\n","545         game       time  3560\n","415         game     please  3420\n","303         game       star  2876\n","...          ...        ...   ...\n","141293     boleh      iaitu     1\n","141294  bercakap      iaitu     1\n","141295       dan      iaitu     1\n","141296     iaitu  terkeluar     1\n","305854     dosen   internet     1\n","\n","[305855 rows x 3 columns]\n","1000 115317\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-71-8ba1fd9a21c9>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-71-8ba1fd9a21c9>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["          term1   term2   freq\n","37         game    play  76797\n","44          fun    game  39451\n","522        game  people  20406\n","749      friend    game  20224\n","531        game    love  19459\n","...         ...     ...    ...\n","368920     keep     ttd      1\n","368921     keep    ttda      1\n","368922     keep   tryna      1\n","368923    berry     ttd      1\n","815814  emotion    work      1\n","\n","[815815 rows x 3 columns]\n","1000 187985\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-71-8ba1fd9a21c9>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-71-8ba1fd9a21c9>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["         term1    term2  freq\n","273       game     play  6368\n","213       game  problem  2852\n","455        fix     game  2809\n","1071      game   please  2663\n","4          fun     game  2603\n","...        ...      ...   ...\n","74135      guy     step     1\n","74134     quit     skin     1\n","74133   avatar     quit     1\n","74130   filter      try     1\n","158667    plan  request     1\n","\n","[158668 rows x 3 columns]\n","1000 80819\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from ast import literal_eval\n","from collections import Counter\n","import csv\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","import itertools\n","\n","# 문자열을 리스트로 변환\n","def str_to_list(x):\n","    try:\n","        return literal_eval(x)\n","    except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기\n","        return None\n","\n","origin_data=pd.read_csv(\"/content/drive/MyDrive/성균관대/zep_selected_4.csv\", low_memory=False)\n","hate_data = origin_data[origin_data['score']<=2]\n","like_data = origin_data[origin_data['score']>=4]\n","medium_data = origin_data[origin_data['score']==3]\n","data_list = [origin_data, hate_data, like_data, medium_data]\n","for idx, data in enumerate(data_list):\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n","  tfidf = TfidfVectorizer()\n","  tdm = tfidf.fit_transform(data['words_selected'])\n","  tf_idf = pd.DataFrame({\n","    '단어': tfidf.get_feature_names_out(),\n","    '빈도': tdm.sum(axis=0).flat})\n","  tf_idf = tf_idf.sort_values('빈도', ascending=False)\n","  tf_idf_dict = tf_idf.set_index('단어')['빈도'].to_dict()\n","  not_remove = dict(itertools.islice(tf_idf_dict.items(), 1000))\n","\n","  count_vec = CountVectorizer()\n","  con = count_vec.fit_transform(data['words_selected'])\n","  word_counts = np.array(con.sum(axis=0)).squeeze()\n","  # 단어-빈도수 사전 생성\n","  c_dict = dict(zip(count_vec.get_feature_names_out(), word_counts))\n","  # 빈도수를 기준으로 내림차순 정렬된 단어-빈도수 사전 생성\n","  c_dict = dict(sorted(c_dict.items(), key=lambda x: x[1], reverse=True))\n","  count = {}   #동시출현 빈도가 저장될 dict\n","  for line in data['words_selected']:\n","      #하나의 문서에서 동일한 단어가 두번 나와도 두번의 동시출현으로 고려X\n","      words = line.split(\" \")\n","      #한줄씩 읽어와서 단어별로 분리(unique한 값으로 받아오기)\n","      #split은 띄어쓰기를 단어로 구분하라는 함수 \n","      \n","      for i, a in enumerate(words):\n","          for b in words[i+1:]:\n","              if a!=b:\n","                if a>b: \n","                    count[b, a] = count.get((b, a),0) + 1  \n","                else :\n","                    count[a, b] = count.get((a, b),0) + 1\n","  df=pd.DataFrame.from_dict(count, orient='index')\n","  df.head()\n","  list1=[]\n","  for i in range(len(df)):\n","    #index를 중심으로 계속 중첩해서 list에 넣는다 \n","    list1.append([df.index[i][0],df.index[i][1],df[0][i]])\n","      \n","  #pandas 이용해서 df형태로 만들기 \n","  df2=pd.DataFrame(list1, columns=[\"term1\",\"term2\",\"freq\"])\n","  #pandas 이용해서 sorting 하기 (디폴트가 오름차순이라서 false 꼭 써줘야 내림차순으로 나옴)\n","  df3=df2.sort_values(by=['freq'],ascending=False)\n","  import numpy as np\n","  import networkx as nx\n","  import operator\n","  G=nx.Graph()\n","  for key in c_dict:\n","      G.add_node(key, tfidf=tf_idf_dict[key], count=c_dict[key])\n","  for i in range(len(df3)):\n","      G.add_edge(df3['term1'][i], df3['term2'][i], weight=int(df3['freq'][i]))\n","  nodes_to_remove = set(G.nodes()) - set(not_remove)  # 제거하지 않을 노드들의 집합\n","  G.remove_nodes_from(nodes_to_remove)\n","  print(len(G.nodes))\n","  if idx ==0:\n","      temp = \"origin\"\n","  if idx == 1:\n","      temp = \"hate\"\n","  if idx == 2:\n","      temp = \"like\"\n","  if idx == 3:\n","      temp = \"medium\"\n","  with open(\"/content/drive/MyDrive/성균관대/github/tf-idf/zep_\"+temp+\"_word_count.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key in c_dict:\n","       writer.writerow([key, c_dict[key]])\n","  with open(\"/content/drive/MyDrive/성균관대/github/tf-idf/zep_\"+temp+\"_tf_idf.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key in tf_idf_dict:\n","       writer.writerow([key, tf_idf_dict[key]])\n","  nx.write_graphml_lxml(G, \"/content/drive/MyDrive/성균관대/github/tf-idf/zep_\"+temp+\"_tf_idf_graph.graphml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHYJDrKZajZ1","executionInfo":{"status":"ok","timestamp":1682535057618,"user_tz":-540,"elapsed":60063,"user":{"displayName":"박선영","userId":"11923719610323479568"}},"outputId":"03270424-613a-430a-d298-c7a3dd09cbf1"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-d60382b56452>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-72-d60382b56452>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["1000\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-d60382b56452>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-72-d60382b56452>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["1000\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-72-d60382b56452>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-72-d60382b56452>:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = [' '.join(row) for row in data['words_selected']]\n"]},{"output_type":"stream","name":"stdout","text":["1000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1yWXdgKu5NKY"},"execution_count":null,"outputs":[]}]}