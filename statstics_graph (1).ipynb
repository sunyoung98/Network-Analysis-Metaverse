{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##그래프 생성하기(hate: 부정리뷰, like: 긍정 리뷰, medium: 3점, origin: 전체)\n","전체 데이터에 대해서 출현빈도가 1000위 이상인 노드들을 기준으로, 단어들의 동시 출현 빈도를 계산하고, 그래프화하였음."],"metadata":{"id":"OrSDbaoyuPQK"}},{"cell_type":"code","source":["import pandas as pd\n","from ast import literal_eval\n","from collections import Counter\n","import csv\n","\n","# 문자열을 리스트로 변환\n","def str_to_list(x):\n","    try:\n","        return literal_eval(x)\n","    except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기\n","        return None\n","origin_data=pd.read_csv(\"/content/drive/MyDrive/성균관대/rob_selected_4.csv\", low_memory=False)\n","hate_data = origin_data[origin_data['score']<=2]\n","like_data = origin_data[origin_data['score']>=4]\n","medium_data = origin_data[origin_data['score']==3]\n","data_list = [origin_data, hate_data, like_data, medium_data]\n","for idx, data in enumerate(data_list):\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","  #data['word_set']=data['words_selected'].apply(lambda x: list(set(x)))\n","  words_list=[]\n","  for i in data['words_selected']:\n","    words_list+=i\n","  c=Counter(words_list)\n","  c_dict= dict(c.most_common(1000))\n","  \n","  count = {}   #동시출현 빈도가 저장될 dict\n","  for line in data['words_selected']:\n","      #하나의 문서에서 동일한 단어가 두번 나와도 두번의 동시출현으로 고려X\n","      words = line\n","      #한줄씩 읽어와서 단어별로 분리(unique한 값으로 받아오기)\n","      #split은 띄어쓰기를 단어로 구분하라는 함수 \n","      \n","      for i, a in enumerate(words):\n","          for b in words[i+1:]:\n","              if a!=b:\n","                if a>b: \n","                    count[b, a] = count.get((b, a),0) + 1  \n","                else :\n","                    count[a, b] = count.get((a, b),0) + 1\n","  df=pd.DataFrame.from_dict(count, orient='index')\n","  df.head()\n","  list1=[]\n","  for i in range(len(df)):\n","    #index를 중심으로 계속 중첩해서 list에 넣는다 \n","    list1.append([df.index[i][0],df.index[i][1],df[0][i]])\n","      \n","  #pandas 이용해서 df형태로 만들기 \n","  df2=pd.DataFrame(list1, columns=[\"term1\",\"term2\",\"freq\"])\n","  #pandas 이용해서 sorting 하기 (디폴트가 오름차순이라서 false 꼭 써줘야 내림차순으로 나옴)\n","  df3=df2.sort_values(by=['freq'],ascending=False)\n","  import numpy as np\n","  import networkx as nx\n","  import operator\n","  G=nx.Graph()\n","  for c in c_dict:\n","      G.add_node(c, weight=c_dict[c])\n","  for i in range(len(df3)):\n","      G.add_edge(df3['term1'][i], df3['term2'][i], weight=int(df3['freq'][i]))\n","  nodes_to_remove = set(G.nodes()) - set(c_dict)  # 제거하지 않을 노드들의 집합\n","  G.remove_nodes_from(nodes_to_remove)\n","  if idx ==0:\n","      temp = \"origin\"\n","  if idx == 1:\n","      temp = \"hate\"\n","  if idx == 2:\n","      temp = \"like\"\n","  if idx == 3:\n","      temp = \"medium\"\n","  with open(\"/content/drive/MyDrive/성균관대/rob_\"+temp+\"_word_count.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key, value in c_dict.items():\n","       writer.writerow([key, value])\n","  nx.write_graphml_lxml(G, \"/content/drive/MyDrive/성균관대/rob_\"+temp+\"_graph.graphml\")"],"metadata":{"id":"29q5Lg0gYb0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682180415187,"user_tz":-540,"elapsed":125585,"user":{"displayName":"박선영","userId":"11923719610323479568"}},"outputId":"92058543-4f12-4334-8e9f-1a5c65cb9397"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-93-82965cc8f83f>:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-93-82965cc8f83f>:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-93-82965cc8f83f>:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n"]}]},{"cell_type":"code","source":["from ast import literal_eval\n","from collections import Counter\n","\n","# 문자열을 리스트로 변환\n","def str_to_list(x):\n","    try:\n","        return literal_eval(x)\n","    except: #해당 값이 null값이거나 오류가 있을 때, None을 return 하기\n","        return None\n","origin_data=pd.read_csv(\"/content/drive/MyDrive/성균관대/zep_selected_4.csv\", low_memory=False)\n","hate_data = origin_data[origin_data['score']<=2]\n","like_data = origin_data[origin_data['score']>=4]\n","medium_data = origin_data[origin_data['score']==3]\n","data_list = [origin_data, hate_data, like_data, medium_data]\n","for idx, data in enumerate(data_list):\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","  #data['word_set']=data['words_selected'].apply(lambda x: list(set(x)))\n","  words_list=[]\n","  for i in data['words_selected']:\n","    words_list+=i\n","  c=Counter(words_list)\n","  c_dict= dict(c.most_common(1000))\n","  \n","  count = {}   #동시출현 빈도가 저장될 dict\n","  for line in data['words_selected']:\n","      #하나의 문서에서 동일한 단어가 두번 나와도 두번의 동시출현으로 고려X\n","      words = line\n","      #한줄씩 읽어와서 단어별로 분리(unique한 값으로 받아오기)\n","      #split은 띄어쓰기를 단어로 구분하라는 함수 \n","      \n","      for i, a in enumerate(words):\n","          for b in words[i+1:]:\n","              if a!=b:\n","                if a>b: \n","                    count[b, a] = count.get((b, a),0) + 1  \n","                else :\n","                    count[a, b] = count.get((a, b),0) + 1\n","  df=pd.DataFrame.from_dict(count, orient='index')\n","  df.head()\n","  list1=[]\n","  for i in range(len(df)):\n","    #index를 중심으로 계속 중첩해서 list에 넣는다 \n","    list1.append([df.index[i][0],df.index[i][1],df[0][i]])\n","      \n","  #pandas 이용해서 df형태로 만들기 \n","  df2=pd.DataFrame(list1, columns=[\"term1\",\"term2\",\"freq\"])\n","  #pandas 이용해서 sorting 하기 (디폴트가 오름차순이라서 false 꼭 써줘야 내림차순으로 나옴)\n","  df3=df2.sort_values(by=['freq'],ascending=False)\n","  import numpy as np\n","  import networkx as nx\n","  import operator\n","  G=nx.Graph()\n","  for c in c_dict:\n","      G.add_node(c, weight=c_dict[c])\n","  for i in range(len(df3)):\n","      G.add_edge(df3['term1'][i], df3['term2'][i], weight=int(df3['freq'][i]))\n","  nodes_to_remove = set(G.nodes()) - set(c_dict)  # 제거하지 않을 노드들의 집합\n","  G.remove_nodes_from(nodes_to_remove)\n","  if idx ==0:\n","      temp = \"origin\"\n","  if idx == 1:\n","      temp = \"hate\"\n","  if idx == 2:\n","      temp = \"like\"\n","  if idx == 3:\n","      temp = \"medium\"\n","  with open(\"/content/drive/MyDrive/성균관대/zep_\"+temp+\"_word_count.csv\", 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key, value in c_dict.items():\n","       writer.writerow([key, value])\n","  nx.write_graphml_lxml(G, \"/content/drive/MyDrive/성균관대/zep_\"+temp+\"_graph.graphml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zapYTHjkuGP8","executionInfo":{"status":"ok","timestamp":1682180669666,"user_tz":-540,"elapsed":60147,"user":{"displayName":"박선영","userId":"11923719610323479568"}},"outputId":"5b440493-9b6f-494f-b12c-4bbdae8abd1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-94-fbf0f5c2c9ff>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-94-fbf0f5c2c9ff>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n","<ipython-input-94-fbf0f5c2c9ff>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['words_selected'] = data['words_selected'].apply(lambda x: str_to_list(x))\n"]}]}]}